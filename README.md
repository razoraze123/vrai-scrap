ğŸ“Œ Description
Ce projet est un scraper web automatisÃ© basÃ© sur Selenium + Python, conÃ§u pour extraire toutes les images haute qualitÃ© de la page produit dâ€™un site e-commerce.
Ce projet a Ã©tÃ© conÃ§u dans le cadre dâ€™un exercice Codex visant Ã  dÃ©montrer la capacitÃ© Ã  :

Manipuler des pages web dynamiques

IntÃ©grer des contre-mesures anti-dÃ©tection

GÃ©rer le tÃ©lÃ©chargement de fichiers distants

Concevoir un code modulaire, maintenable et professionnel

ğŸ¯ Objectif
Extraire automatiquement toutes les images de la galerie produit visible sur la page suivante :
https://bob-crew.com/products/bob-ficelle-outdoor

Ces images sont ensuite enregistrÃ©es localement dans un dossier dÃ©diÃ©. Le script peut facilement Ãªtre adaptÃ© Ã  d'autres pages produits du mÃªme site (ou dâ€™autres sites similaires) en changeant simplement lâ€™URL.

âš™ï¸ Technologies utilisÃ©es
Composant	RÃ´le
Selenium	Navigation et manipulation de DOM dynamique
webdriver-manager	Installation automatique de ChromeDriver
requests	TÃ©lÃ©chargement des images
Python 3.8+	Langage utilisÃ©
CSS Selectors	Pour cibler les Ã©lÃ©ments DOM

ğŸ› ï¸ Installation
Cloner le repo

bash
Copier
Modifier
git clone https://github.com/ton-utilisateur/product-image-scraper.git
cd product-image-scraper
CrÃ©er un environnement virtuel (optionnel mais recommandÃ©)

bash
Copier
Modifier
python3 -m venv venv
source venv/bin/activate  # Sur macOS/Linux
# venv\Scripts\activate    # Sur Windows
Installer les dÃ©pendances

bash
Copier
Modifier
pip install -r requirements.txt
Note : Pas besoin dâ€™installer manuellement ChromeDriver. Le script utilise webdriver-manager qui dÃ©tecte ta version de Chrome et installe le bon driver automatiquement.

ğŸš€ Utilisation
Lance le script en fournissant l'URL de la page produit :

```bash
python scrape_images.py https://exemple.com/ma-page-produit
```

Tu peux indiquer un sÃ©lecteur CSS personnalisÃ© :

```bash
python scrape_images.py https://exemple.com/ma-page-produit \
  --selector "div.gallery img"
```

Et choisir un dossier de sortie diffÃ©rent :

```bash
python scrape_images.py https://exemple.com/ma-page-produit \
  --selector "div.gallery img" --output-dir mes_images
```

Par dÃ©faut, le sÃ©lecteur utilisÃ© est `div[data-media-type='image'] img` et les images sont enregistrÃ©es dans `./images`.

ğŸ–¥ï¸ Interface graphique
Une fenÃªtre Tkinter permet de lancer le scraping sans passer par la ligne de
commande. Lance simplement `interface.py`, saisis l'URL du produit puis clique
sur **Scraper les images**. Les messages du script apparaÃ®tront directement dans
la fenÃªtre. Aucune dÃ©pendance externe n'est requise pour cette interface.

ğŸ“ Structure du projet
bash
Copier
Modifier
.
â”œâ”€â”€ scrape_images.py         # Script principal
â”œâ”€â”€ interface.py             # Petite interface Tkinter
â”œâ”€â”€ README.md                # Ce fichier
â”œâ”€â”€ requirements.txt         # DÃ©pendances Python
â””â”€â”€ images/                  # Dossier gÃ©nÃ©rÃ© avec toutes les images rÃ©cupÃ©rÃ©es
ğŸ” Contournement de lâ€™anti-scraping
Le projet inclut :

Suppression de navigator.webdriver

Suppression de lâ€™extension enable-automation

DÃ©lai random.uniform pour simuler le comportement humain

Ces stratÃ©gies permettent de rendre le scraping moins dÃ©tectable sur des sites utilisant des vÃ©rifications JS basiques.

âœ… RÃ©sultat attendu
AprÃ¨s exÃ©cution, tu obtiens :

text
Copier
Modifier
ğŸ“¸ 6 images trouvÃ©es.
â¬‡ï¸ TÃ©lÃ©chargement image 1: https://...
â¬‡ï¸ TÃ©lÃ©chargement image 2: https://...
...
âœ… Toutes les images ont Ã©tÃ© enregistrÃ©es dans le dossier ./images
ğŸ“Œ Pourquoi ce projet est pertinent pour Codex ?
ğŸ¯ CiblÃ© : extraction dâ€™un contenu utile (assets produits) en e-commerce

ğŸ§  Robuste : rÃ©siste aux mÃ©canismes simples dâ€™anti-bot

âš™ï¸ Modulaire : facilement adaptable Ã  dâ€™autres cas de scraping

ğŸ’¡ Best practices : structure claire, logique propre, README documentÃ©

ğŸš« Ã‰thique : respecte robots.txt du site et ne scrape que des pages autorisÃ©es

ğŸ“¬ Auteur
ğŸ”§ Construit par [Ton Nom / Ton Pseudo GitHub]
ğŸ“« Contact : [email / GitHub / LinkedIn selon prÃ©fÃ©rence]

